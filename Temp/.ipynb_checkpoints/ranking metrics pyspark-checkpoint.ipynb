{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2d5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType\n",
    "import time\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RankingMetrics \n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47814e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "#A class used to preprocess data and to return train/val/test splits\n",
    "class DataPreprocessor():\n",
    "    def __init__(self, spark, file_path) -> None:\n",
    "        self.spark = spark                              #Spark Driver\n",
    "        self.file_path = file_path                      #File Path to Read in Data\n",
    "\n",
    "\n",
    "    #Main Method - Call this in partition_data.py to get train/val/test splits returned\n",
    "    def preprocess(self, sanity_checker=False):\n",
    "        \"\"\"\n",
    "        Goal: Save train/val/test splits to netID/scratch - all using self methods\n",
    "        Step 1: self.clean_data: clean the data, format timestamp to date, and remove duplicate movie titles\n",
    "        Step 2: self.create_train_val_test_splits: reformats data, drops nans, and returns train,val and test splits\n",
    "        input:\n",
    "        -----\n",
    "        sanity_checker: boolean - Flag that decides if we call self.sanity_check()\n",
    "        -----\n",
    "        output: \n",
    "        train: RDD of Training Set Data\n",
    "        val: RDD of Validation Set Data\n",
    "        test: RDD of Validation Set Data\n",
    "        \"\"\"\n",
    "        #Format Date Time and Deduplicate Data\n",
    "        clean_data = self.clean_data()                                                  #No args need to be passed, returns RDD of joined data (movies,ratings), without duplicates\n",
    "        #Get Utility Matrix\n",
    "        train, val, test = self.create_train_val_test_splits(clean_data)                #Needs clean_data to run, returns train/val/test splits\n",
    "        \n",
    "        #Check if we should perform sanity check\n",
    "        if sanity_checker:\n",
    "            flag = self.sanity_check(train,val,test)\n",
    "            #If flag == True we're good\n",
    "            if flag:\n",
    "                print(\"The val and test splits are disjoint!\")\n",
    "            #Otherwise raise exception\n",
    "            else:\n",
    "                raise Exception(\"The Validation and Test sets are not disjoint!\")\n",
    "\n",
    "        #Return train val test sets\n",
    "        return train, val, test\n",
    "    \n",
    "    #preprocess calls this function\n",
    "    def clean_data(self):\n",
    "        \"\"\"\n",
    "        goal: for movie titles with multiple movieIDs, in the movies dataset,\n",
    "        remove the duplicate IDs with the least ratings for each movie. \n",
    "        Additionally, remove those IDs from the ratings dataset, so we get a 1:1 mapping\n",
    "        between movie title and movie ID\n",
    "\n",
    "        inputs: None, however - self.file_path -> this should link to your hfs/netid/\n",
    "        outputs: all_data - a RDD of joined data (movies,reviews) - deduplicated of titles that appear more than once\n",
    "                this loses only 6 records (reviews from users) for small\n",
    "        \"\"\"\n",
    "\n",
    "        #Import the movies data + add to schema so it can be used by SQL + header=True because there's a header\n",
    "        movies = self.spark.read.csv(self.file_path + 'movies.csv', header=True, \\\n",
    "                                    schema='movieId INT, title STRING, genres STRING')\n",
    "    \n",
    "        #Same for ratings - TIMESTAMP MUST BE STRING\n",
    "        ratings = self.spark.read.csv(self.file_path + 'ratings.csv', header=True, \\\n",
    "                    schema='userId INT, movieId INT, rating FLOAT, timestamp STRING') \n",
    "        \n",
    "        #Get the MM-dd-yyyy format for timestamp values producing new column, Date\n",
    "        ratings = ratings.withColumn(\"date\",from_unixtime(col(\"timestamp\"),\"MM-dd-yyyy\"))\n",
    "        ratings = ratings.drop(\"timestamp\") #Drop timestamp, we now have date\n",
    "\n",
    "        #Join Dfs - Join Movies with Ratings on movieId, LEFT JOIN used, select only rating, userId, movieId, title and date\n",
    "        joined = ratings.join(movies, ratings.movieId==movies.movieId, how='left').select(\\\n",
    "                            ratings.rating,ratings.userId,\\\n",
    "                            ratings.movieId,ratings.date,movies.title)\n",
    "\n",
    "        #Find Movie Titles that map to multiple IDs\n",
    "        dupes = joined.groupby(\"title\").agg(countDistinct(\"movieId\").alias(\"countD\")).filter(col(\"countD\")>1)\n",
    "\n",
    "        #Isolate non-dupes into a df\n",
    "        non_dupes = joined.join(dupes, joined.title==dupes.title, how='leftanti')\n",
    "    \n",
    "        #Get all of the dupes data - ratings, userId, ect - again from Joined\n",
    "        dupes = dupes.join(joined, joined.title==dupes.title, how='inner').select(\\\n",
    "                                        joined.movieId,joined.rating,\\\n",
    "                                        joined.date,dupes.title,joined.userId)\n",
    "    \n",
    "        #Clean the dupes accordingly\n",
    "        #Step 1: Aggregate by title/movie Id, then count userId - give alias\n",
    "        #Step 2: Create a window to partition by - we iterate over titles ranking by \n",
    "        #countD (count distinct of userId) - movieId forces a deterministic ranking based off movieId\n",
    "        #Step 3: Filter max_dupes so we only grab top ranking movieIds\n",
    "        windowSpec = Window.partitionBy(\"title\").orderBy(\"countD\",\"movieId\")\n",
    "        max_dupes = dupes.groupBy([\"title\",\"movieId\"]).agg(countDistinct(\"userId\").alias(\"countD\"))\n",
    "        max_dupes = max_dupes.withColumn(\"dense_rank\",dense_rank().over(windowSpec))\n",
    "        max_dupes = max_dupes.filter(max_dupes.dense_rank==\"2\")\n",
    "        max_dupes = max_dupes.drop(\"countD\",\"dense_rank\")\n",
    "        \n",
    "        #Get a list of movie ids ~len(5) for small - which are the ones we want to keep\n",
    "        ids = list(max_dupes.toPandas()['movieId'])\n",
    "        cleaned_dupes = dupes.where(dupes.movieId.isin(ids))\n",
    "        \n",
    "        #Reorder Columns so union works\n",
    "        cleaned_dupes = cleaned_dupes.select('rating', 'userId', 'movieId', 'date', 'title')\n",
    "\n",
    "        \n",
    "        #Get the union of the non_dupes and cleaned_dupes\n",
    "        clean_data = non_dupes.union(cleaned_dupes)\n",
    "\n",
    "        #Subtract 2.5 from each review to create negative reviews\n",
    "        clean_data = clean_data.withColumn(\"rating\",col(\"rating\")-2.5)\n",
    "        \n",
    "        #For testing purposes should be 100,830 for small dataset\n",
    "        #print(f\"The length of the combined and de-deduped joined data-set is: {len(clean_data.collect())}\")\n",
    "\n",
    "        #Repartition for efficiency:\n",
    "        clean_data = clean_data.repartition(30)\n",
    "\n",
    "        #Return clean_data -> Type: Spark RDD Ready for more computation\n",
    "        return clean_data\n",
    "\n",
    "    #Create Train Test Val Splits - .preprocess() calls this function\n",
    "    def create_train_val_test_splits(self, clean_data):\n",
    "        \"\"\"\n",
    "        Procedure: \n",
    "        Create two columns - the first will measure the specific row count for a specific user\n",
    "        the other will be static fixed at the total number of reviews for that user. The row count\n",
    "        is sorted by date ascending, so the first row is the oldest review.\n",
    "        \n",
    "        Then, subset training to be where row_count <= .6 *length, grabbing the oldest 60% of reviews, for\n",
    "        all users.\n",
    "        \n",
    "        We then subset the remaining data into a hold out, with the goal of creating two disjoint validation\n",
    "        and test data sets when looking at userId (meaning they should not have any shared userId values), \n",
    "        but still have roughly the same amount of data, or whatever percentage we want to achieve\n",
    "        \n",
    "        To obtain approximate equality and disjoint userId membership, for the remiaining data\n",
    "        sort userId by user_review_count descending, then alternate values in that list, assigning\n",
    "        half to test and half to validation.\n",
    "        -----\n",
    "        input: RDD created by joining ratings.csv and movies.csv - cleaned of duplicates and formatted accordingly\n",
    "        -----\n",
    "        -----\n",
    "        output: training 60%, val 20%, test 20% splits with colums cast to integer type and na's dropped\n",
    "        -----\n",
    "        \"\"\"\n",
    "        #Type Cast the cols to numeric\n",
    "        ratings = clean_data.withColumn('movieId',col('movieId').cast(IntegerType())).withColumn(\"userId\",col(\"userId\").cast(IntegerType()))\n",
    "        #Drop nulls\n",
    "        ratings = clean_data\n",
    "        ratings = ratings.na.drop(\"any\")\n",
    "    \n",
    "        #strategy, partition by userId, and userId order by date, \n",
    "        #take the first 60% of reviews for all users\n",
    "        w1 = Window.partitionBy(\"userId\")\n",
    "        w2 = Window.partitionBy(\"userId\").orderBy(\"date\")\n",
    "        ratings = (ratings.withColumn(\"row_num\", row_number().over(w2))\n",
    "                       .withColumn('length', count('userId').over(w1))\n",
    "                  )\n",
    "\n",
    "        #store in training RDD by \n",
    "        #selecting all rows where the row_count for that user <= 60% total reviews for that user\n",
    "        \n",
    "        training = ratings.filter(\"row_num <=.6*length\")\n",
    "        #now for validation and test set, we want those to have no users in common, but for them to\n",
    "        #be approximately equal size. \n",
    "        holdout_df = ratings.filter(\"row_num >.6*length\")\n",
    "        \n",
    "        #strategy, of the data not in my train set, group users by number of movies they have seen\n",
    "        #sort descending\n",
    "        holdout_split = holdout_df.groupBy(\"userId\").count().orderBy(\"count\", ascending=False).toPandas()\n",
    "        \n",
    "        #store the list of userIds sorted by descending total movie count\n",
    "        holdout_split = list(holdout_split.userId)\n",
    "        \n",
    "        #partition list of userIds by taking every other index and putting it in the validation set\n",
    "        val_users = holdout_split[::2]\n",
    "        \n",
    "        #create a validation and test set by filtering holdout data based on whether movieId isin val_users\n",
    "        val = holdout_df.filter(holdout_df.userId.isin(val_users))\n",
    "        test = holdout_df.filter(~holdout_df.userId.isin(val_users))\n",
    "\n",
    "        #Repartition for efficiency\n",
    "        training = training.coalesce(1)\n",
    "        val = val.coalesce(1)\n",
    "        test = test.coalesce(1)\n",
    "        #Return train/val/test splits\n",
    "        return training, val, test\n",
    "\n",
    "    #TO DO?? Should we enforce min_review cutoff to make sure no cold-start for any prediction?\n",
    "    def enforce_min_review(self):\n",
    "        pass\n",
    "    \n",
    "    def train_leakage_check(self,train,val):\n",
    "        \"\"\"\n",
    "\n",
    "        returnFlag: boolean - True means test and val splits are disjoint on userId\n",
    "        \"\"\"\n",
    "\n",
    "        #Get observatio counts for training, val, and test sets\n",
    "        training_obs = train.count()\n",
    "        val_obs = val.count()\n",
    "\n",
    "        #Print them out\n",
    "        print(f\"Training Data Len: {training_obs} Val Len: {val_obs}\")\n",
    "        #Check if there are any overlapping_ids in the sets\n",
    "        cond = [train.userId == val.userId, train.movieId == val.movieId]\n",
    "        overllaping_ids = train.join(val, cond,how='inner').count()\n",
    "        if overllaping_ids != 0:\n",
    "            overlap = train.join(val, cond,how='inner').select(val.userId,val.movieId).collect()\n",
    "            overlap = [(x[0],x[1]) for x in overlap]\n",
    "            print(f\"Overlapping movieIds: {overlap}\")\n",
    "        #Return True if they're disjoint, False if there's overlap\n",
    "        return overllaping_ids == 0\n",
    "\n",
    "    #Check to train/val/test splits to make sure approx 60/20/20 split is achieved\n",
    "    def sanity_check(self,train,val,test):\n",
    "        \"\"\"\n",
    "        Method to print out the shape of train/val/test splits, and a check to make sure that\n",
    "        val and test splits are disjoint (no distinct userId appears in both)\n",
    "        input:\n",
    "        -----\n",
    "        train: RDD - Training data split created from .create_train_val_test_splits\n",
    "        val: RDD - Validation data split created from .create_train_val_test_splits\n",
    "        test: RDD - Testing data split created from .create_train_val_test_splits\n",
    "        -----\n",
    "        output:\n",
    "        -----\n",
    "        returnFlag: boolean - True means test and val splits are disjoint on userId\n",
    "        \"\"\"\n",
    "\n",
    "        #Get observatio counts for training, val, and test sets\n",
    "        training_obs = train.count()\n",
    "        val_obs = val.count()\n",
    "        test_obs = test.count()\n",
    "        \n",
    "        print(f\"Train/Val Leakage test result: (True is good) {self.train_leakage_check(train,val)}\")\n",
    "        #Print them out\n",
    "        print(f\"Training Data Len: {training_obs} Val Len: {val_obs}, Test Len: {test_obs}\")\n",
    "        print(f\"Partitions, Train: {train.rdd.getNumPartitions()}, Val: {val.rdd.getNumPartitions()}, Test: {test.rdd.getNumPartitions()}\")\n",
    "        #Check if there are any overlapping_ids in the sets\n",
    "        overllaping_ids = val.join(test, test.userId==val.userId,how='inner').count()\n",
    "        \n",
    "        #Return True if they're disjoint, False if there's overlap\n",
    "        return overllaping_ids == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ad362c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "class Model():\n",
    "    \"\"\"\n",
    "    Abstract Model class that will contain various methods to deploy collaborative filtering.\n",
    "    Model Parameters that need to be passed thorugh:\n",
    "    ### For ALS Model ###\n",
    "    -----\n",
    "    rank: int - Rank of latent factors used in decomposition\n",
    "    maxIter: int - represents number of iterations to run algorithm\n",
    "    regParam: float - Regularization Parameter\n",
    "    model_save: boolean - Flag to determine if we should save the model progress or not\n",
    "    -----\n",
    "    ### For baseline Model ###\n",
    "    -----\n",
    "    min_ratings: int - Minimum number of reviews to qualify for baseline (Greater Than or Equal to be included)\n",
    "    -----\n",
    "    ### No Input Necessary ###\n",
    "    -----\n",
    "    model_size: str - Either \"large\" or \"small\" used to demarcate which dataset we are running on\n",
    "    model_type: str - Which model type we intent to run, i.e. ALS or baseline\n",
    "    evaluation_data_name: str - Dummy variable used to keep track of which dataset we are making predictions on, either \"Val\" or \"Test\"\n",
    "    time_when_ran: datetime - Time when model was run\n",
    "    time_to_fit: datetime - Time it took to fit the model\n",
    "    time_to_predict: datetime - Time it took to make predictions\n",
    "    metrics: dict - Dictionary used to store the various metrics calculated in self.record_metrics()\n",
    "    -----\n",
    "    ### Misc ###\n",
    "    -----\n",
    "    num_recs: int - Top X number of reccomendations to return - default set to 100\n",
    "    -----\n",
    "    ### Model Methods ###\n",
    "    -----\n",
    "    run_model: Runs the corresponding method that was passed to self.model_type\n",
    "    alternatingLeastSquares: Latent Factor model which uses the Alternating Least Squares Pyspark Class to fit and predict.\n",
    "    baseline: uses a baseline popularity model that returns the top X most popular movies (decided by avg rating per movie)\n",
    "    record_metrics: Calculates metrics for prediction,label pairs\n",
    "    save_model: Used for advanced models like ALS or extensions where we may want to save the model itself\n",
    "    -----\n",
    "    \"\"\"\n",
    "\n",
    "    # Constructor for Model\n",
    "    def __init__(self, model_size=None, model_type=None, rank=None, maxIter=None, regParam=None,\n",
    "                 model_save=False, num_recs=100, min_ratings=0, positive_rating_threshold = 0):\n",
    "        # Model Attributes\n",
    "        # NO Arg needed to be passed thorugh\n",
    "        # Dictionary to access variable methods\n",
    "        self.methods = {\"als\": self.alternatingLeastSquares,\n",
    "                        \"baseline\": self.baseline}\n",
    "        # Top X number of reccomendations to return - set to 100, probably won't change\n",
    "        self.num_recs = num_recs\n",
    "\n",
    "        # Passed through by user\n",
    "        self.model_size = model_size\n",
    "        self.model_type = model_type\n",
    "        self.positive_rating_threshold = positive_rating_threshold\n",
    "\n",
    "        # For ALS\n",
    "        self.rank = rank  # Rank of latent factors used in decomposition\n",
    "        self.maxIter = maxIter  # Number of iterations to run algorithm, recommended 5-20\n",
    "        self.regParam = regParam  # Regularization Parameter\n",
    "        # (Optional) Flag used to determine whether or not we should save our model somewhere\n",
    "        self.model_save = model_save\n",
    "\n",
    "        # For baseline\n",
    "        # Minimum number of reviews to qualify for baseline (Greater Than or Equal to be included)\n",
    "        self.min_ratings = min_ratings\n",
    "\n",
    "        # Add the attributes we're gonna compute when we fit and predict\n",
    "        self.evaluation_data_name = None\n",
    "        self.time_when_ran = None\n",
    "        self.time_to_fit = None\n",
    "        self.time_to_predict = None\n",
    "        self.metrics = {}\n",
    "\n",
    "    def run_model(self, train, val=None, test=None):\n",
    "        \"\"\"\n",
    "        Run_model is what is called to fit, run, and record the metrics for respective model types.\n",
    "        Function behavior is dependent on the argument passed to self.model_type.\n",
    "        -----\n",
    "        inputs:\n",
    "        -----\n",
    "        train: RDD - Training data set\n",
    "        val: RDD - Validation data set\n",
    "        test: RDD - Test set\n",
    "        -----\n",
    "        outputs:\n",
    "        -----\n",
    "        model_output: Variable Type - Output of whichever model ran -> check self.model_type\n",
    "        -----\n",
    "        \"\"\"\n",
    "        # Get when model was ran\n",
    "        self.time_when_ran = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "        # Identify if we're predicting on the Validation Set or the Test Set\n",
    "        if val:\n",
    "            self.evaluation_data_name = \"Val\"\n",
    "            evaluation_data = val\n",
    "        elif test:\n",
    "            self.evaluation_data_name = \"Test\"\n",
    "            evaluation_data = test\n",
    "\n",
    "        # Grab method for whichever model corresponds to self.model_type\n",
    "        model = self.methods[self.model_type]\n",
    "        # Run model on training / evaluation data\n",
    "        model_output = model(train, evaluation_data)\n",
    "        # Return model output\n",
    "        return model_output\n",
    "\n",
    "    # This method uses the Alternating Least Squares Pyspark Class to fit and run a model\n",
    "    def alternatingLeastSquares(self, training, evaluation_data):\n",
    "        \"\"\"\n",
    "        Builds and fits a PySpark alternatingLeastSquares latent factor model. Calls self.record_metrics(precitions,labels)\n",
    "        to record the results. Some dummy variables are made to record whether or not we are using the validation set\n",
    "        or the testing set. This will help us record our results accurately. Training and predicting are also timed. \n",
    "        -----\n",
    "        Input: \n",
    "        training: RDD - Training data set\n",
    "        evaluation_data: RDD - Either Validation data set, or Training data set\n",
    "        -----\n",
    "        Output: [userRecs, movieRecs] - list containing two lists, each of length == self.numrecs \n",
    "        -----\n",
    "        \"\"\"\n",
    "\n",
    "        # Time the function start to finish\n",
    "        start = time.time()\n",
    "        # Create the model with certain params - coldStartStrategy=\"drop\" means that we'll have no nulls in val / test set\n",
    "        als = ALS(maxIter=self.maxIter, rank=self.rank, regParam=self.regParam,\n",
    "                  nonnegative=False, seed=10, userCol=\"userId\",\n",
    "                  itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "        # Fit the model\n",
    "        model = als.fit(training)\n",
    "        # End time and calculate delta\n",
    "        end = time.time()\n",
    "        self.time_to_fit = end - start\n",
    "\n",
    "        # Time predictions as well\n",
    "        start = time.time()\n",
    "        regression_predictions = model.transform(evaluation_data)\n",
    "        #Generate 100 Top Movies for All Users\n",
    "        userRecs = model.recommendForAllUsers(self.num_recs)\n",
    "        #Unpack userRecs, go from userId, list({movieId:predicted_rating}) -> userId, movieId\n",
    "        ranking_predictions = userRecs.select(\"userId\",explode(\"recommendations.movieId\"))\n",
    "        end = time.time()\n",
    "        self.time_to_predict = end - start\n",
    "\n",
    "        # Use self.record_metrics to evaluate model on Precision at K, Mean Precision, and NDGC\n",
    "        self.ranking_metrics(predictions=ranking_predictions, labels=evaluation_data)\n",
    "        #Use self.non_ranking_metrics to compute RMSE, R^2, and ROC of Top 100 Predictions - No special Filtering ATM\n",
    "        self.non_ranking_metrics(regression_predictions)        \n",
    "        \n",
    "\n",
    "        # Save model if we need to\n",
    "        if self.model_save:\n",
    "            self.save_model(model_type=self.model_type, model=als)\n",
    "\n",
    "        # Return top self.num_recs movie recs for each user\n",
    "        return userRecs\n",
    "\n",
    "    # Baseline model that returns top X most popular items (highest avg rating)\n",
    "    def baseline(self, training, evaluation_data):\n",
    "        \"\"\"\n",
    "        Baseline model for recommendation system. No personalization, just recommend the Top 100 movies by avg(rating)\n",
    "        A movie must have at least self.min_ratings to be considered\n",
    "        input:\n",
    "        -----\n",
    "        training: RDD - training set data\n",
    "        evaluation_data: RDD - Validation set or Test set data\n",
    "        self.min_ratings: int - how many ratings a movie must have in order to be considered in top 100\n",
    "        -----\n",
    "        output: RDD of Top 100 movieIds by avg(rating)\n",
    "        \"\"\"\n",
    "        #Make sure the right params have been passed to Model()\n",
    "        if self.min_ratings is None:\n",
    "            raise Exception(\"Must pass through a value for self.min_ratings for baselien to compute\")\n",
    "\n",
    "        # Time model Fit\n",
    "        start = time.time()\n",
    "        # Get Top 100 Most Popular Movies - Avg(rating) becomes prediction\n",
    "        temp = training\n",
    "        top_100_movies = temp.groupBy(\"movieId\").agg(avg(\"rating\").alias(\"prediction\"),count(\"movieId\").alias(\"movie_count\"))\n",
    "        top_100_movies = top_100_movies.where(col(\"movie_count\")>=self.min_ratings)\n",
    "        top_100_movies = top_100_movies.select(\"movieId\").orderBy(\"prediction\", ascending=False).limit(100)\n",
    "        \n",
    "        # Grab Distinct User Ids\n",
    "        temp2 = evaluation_data\n",
    "        ids = temp2.select(\"userId\").distinct()\n",
    "        # Cross Join Distinct userIds with Top 100 Most Popular Movies\n",
    "        predictions = ids.crossJoin(top_100_movies)\n",
    "        # Record end time after RDD operations\n",
    "        end = time.time()\n",
    "        self.time_to_fit = end - start\n",
    "\n",
    "        # Time predictions as well\n",
    "        self.time_to_predict = 0  # Recommends in constant time\n",
    "        returned_df = predictions.alias(\"returned_df\")\n",
    "        predictions.unpersist()\n",
    "        return returned_df\n",
    "        # Use self.record_metrics to evaluate model on RMSE, R^2, Precision at K, Mean Precision, and NDGC\n",
    "        return self.ranking_metrics(predictions=predictions, labels=evaluation_data)\n",
    "\n",
    "        self.metrics['precision'] = precision\n",
    "        self.metrics['MAP'] = MAP\n",
    "\n",
    "        # Return The top 100 most popular movies above self.min_ratings threshold\n",
    "        return top_100_movies\n",
    "\n",
    "    #Non-Ranking Metrics Calculated Here\n",
    "    def non_ranking_metrics(self,predictions):\n",
    "        ##Evaluate Predictions for Regression Task##\n",
    "        evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "        # Calculate RMSE and r_2 metrics and append to metrics\n",
    "        self.metrics[\"rmse\"] = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "        self.metrics[\"r2\"] = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "        ##ROC Metric Evaluation##\n",
    "        # Make predictions Binary\n",
    "        binary_predicts = predictions.withColumn(\"prediction\", when(predictions.rating > 0, 1).otherwise(0).cast(\"double\"))\n",
    "        evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='rating', metricName='areaUnderROC')\n",
    "        # Append ROC to our Metrics list\n",
    "        self.metrics[\"ROC\"] = evaluator.evaluate(binary_predicts)\n",
    "\n",
    "    def ranking_metrics(self, predictions, labels):\n",
    "        \"\"\"\n",
    "        Method that will contain all the code to evaluate model on metrics: RMSE, R^2, ROC, Precistion At K, Mean Precision, and NDGC\n",
    "        input:\n",
    "        -----\n",
    "        predictions: RDD - PySpark Dataframe containing the following columns at the minimum: [userId,movieId,prediction] - if not baseline model must include rating column\n",
    "        labels: RDD - PySpark Dataframe containing the following columns at the minimum: [userId,movieId,rating, date]\n",
    "        -----\n",
    "        returns: \n",
    "        None - Writes the results to self.metrics dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        #Join labels and predictions on [userId,movieId]\n",
    "        label_inner_predictions = labels.join(predictions, ['userId', 'movieId'], how ='inner').select('userId', 'movieId', \"rating\")\n",
    "\n",
    "        #Collect ratings by userId where the rating is above some self.review_score_threshold -> userId, [movie1,...movieN]\n",
    "        pos_label_inner_prediction = label_inner_predictions.where(f\"rating>{self.positive_rating_threshold}\"\\\n",
    "                                            ).groupBy('userId').agg(expr('collect_list(movieId) as movieId'))\n",
    "        label_inner_predictions = label_inner_predictions.groupBy('userId').agg(expr('collect_list(movieId) as movieId'))\n",
    "        \n",
    "        ranking_metrics_data = label_inner_predictions.join(\n",
    "                pos_label_inner_prediction, 'userId').rdd.map(lambda row: (row[1], row[2]))\n",
    "        \n",
    "        ranking_metrics_data = ranking_metrics_data.coalesce(1)\n",
    "        \n",
    "        return ranking_metrics_data\n",
    "        #Get RankingMetrics object\n",
    "        metrics = RankingMetrics(ranking_metrics_data)\n",
    "        #Calculate MAP\n",
    "        # self.metrics['Precision - Intersection'] = metrics.recallAt(self.num_recs)\n",
    "        # self.metrics['MAP - Intersection'] = metrics.meanAveragePrecision\n",
    "        precision = metrics.recallAt(self.num_recs)\n",
    "        MAP = metrics.meanAveragePrecision\n",
    "\n",
    "        return precision,MAP\n",
    "    # Method to save model to const.MODEL_SAVE_FILE_PATH\n",
    "    def save_model(self, model_type=None, model=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        -----\n",
    "        model_type: str - string designating what type of model is being saved\n",
    "        model: obj - model object that has .save method\n",
    "        -----\n",
    "        \"\"\"\n",
    "        # Make sure a non-null object was passed\n",
    "        if model and model_type:\n",
    "            model.save(const.MODEL_SAVE_FILE_PATH + model_type)\n",
    "        # Otherwise throw error\n",
    "        else:\n",
    "            raise Exception(\"Model and or Model_type not passed through\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2baf45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_checker(rdd):\n",
    "    rdd = rdd.collect()\n",
    "    for row in rdd:\n",
    "        for val in row[2]:\n",
    "            if val not in row[1]:\n",
    "                raise Exception(f\"Error raised at {row[1]} movieId:{val}\")\n",
    "\n",
    "def prediction_checker(predicts,val,min_reviews):\n",
    "    \"\"\"\n",
    "    predicts: RDD - Tuples of \n",
    "    (userId, [intersected predicted positive labels],[ground truth intersected positive labels])\n",
    "    Check that precision score is correct by \n",
    "    For everything in the predicted set that shows up in RDD, verify that the user liked it in val\n",
    "    \"\"\"\n",
    "    #Make correct format\n",
    "    predicts = predicts.collect()\n",
    "    val = val.where(col(\"rating\")>=min_reviews)\n",
    "    df = val.toPandas()\n",
    "    #Dummy Variables\n",
    "    correct, not_correct = 0,0\n",
    "    #Iterate and ensure precision\n",
    "    for row in predicts:\n",
    "        for movie in row[1]:\n",
    "            testy = df[(df['movieId']==movie)&(df['userId']==row[0])]\n",
    "            if len(testy) > 0:\n",
    "                correct+=1\n",
    "            else:\n",
    "                print(f\"User: {row[0]} Movie: {movie}\")\n",
    "                not_correct+=1\n",
    "    #Return Precision TP / (TP+FP)\n",
    "    return (correct / (correct+not_correct))\n",
    "\n",
    "def baseline_prediction_check(preds):\n",
    "    x = preds.groupBy(\"movieId\").count().collect()\n",
    "    y = np.array([int(y[1]) for y in x])\n",
    "    if y.sum()/len(y) != 305:\n",
    "        raise Exception(f\"Baseline Predicts are Wrong, movieId count = {y.sum()}, len:{len(y)}\")\n",
    "    x = preds.groupBy(\"userId\").count().collect()\n",
    "    y = np.array([int(y[1]) for y in x])\n",
    "    if y.sum()/len(y) != 100:\n",
    "        raise Exception(f\"Baseline predictions are wrong, userId count = {y.sum()}, len:{len(y)}\")\n",
    "    print(\"Passed Baseline Prediction Check\")\n",
    "    \n",
    "\n",
    "def train_leakage_check(train,val):\n",
    "    \"\"\"\n",
    "\n",
    "    returnFlag: boolean - True means test and val splits are disjoint on userId\n",
    "    \"\"\"\n",
    "\n",
    "    #Get observatio counts for training, val, and test sets\n",
    "    training_obs = train.count()\n",
    "    val_obs = val.count()\n",
    "\n",
    "    #Print them out\n",
    "    print(f\"Training Data Len: {training_obs} Val Len: {val_obs}\")\n",
    "    #Check if there are any overlapping_ids in the sets\n",
    "    cond = [train.userId == val.userId, train.movieId == val.movieId]\n",
    "    overllaping_ids = train.join(val, cond,how='inner').count()\n",
    "    if overllaping_ids != 0:\n",
    "        overlap = train.join(val, cond,how='inner').select(val.userId,val.movieId).collect()\n",
    "        overlap = [(x[0],x[1]) for x in overlap]\n",
    "        print(f\"Overlapping movieIds: {overlap}\")\n",
    "    #Return True if they're disjoint, False if there's overlap\n",
    "    return overllaping_ids == 0\n",
    "\n",
    "def dupe_checker(dataFrame):\n",
    "\n",
    "    a=dataFrame.select(col(\"userId\"),col(\"movieId\")).collect()\n",
    "    seen = dict()\n",
    "\n",
    "    for row in a:\n",
    "\n",
    "        if (row[0],row[1]) not in seen:\n",
    "            seen[(row[0],row[1])] =1\n",
    "\n",
    "        else:\n",
    "            print(f\"Dupe found at: userId:{row[0]},movieId:{row[1]}\")\n",
    "\n",
    "    print(f\"len of keys: {len(list(seen.keys()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fffb890",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder_path = \"../../ml-latest-small/\"\n",
    "spark = SparkSession.builder.appName('Spark_Session_Name').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9564d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Len: 60250 Val Len: 20510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Leakage test result: (True is good) True\n",
      "Training Data Len: 60250 Val Len: 20510, Test Len: 20070\n",
      "Partitions, Train: 1, Val: 1, Test: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:=================================================>   (371 + 11) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val and test splits are disjoint!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train, val, test = DataPreprocessor(spark,folder_path).preprocess(sanity_checker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05623854",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(model_type='baseline', min_ratings=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "738d1812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 261:=============================>                      (230 + 11) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed Baseline Prediction Check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "temp = m.baseline(train,val)\n",
    "baseline_prediction_check(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf8cb022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[496,\n",
       " 3475,\n",
       " 8911,\n",
       " 113829,\n",
       " 152711,\n",
       " 5513,\n",
       " 4294,\n",
       " 84273,\n",
       " 633,\n",
       " 5222,\n",
       " 6732,\n",
       " 876,\n",
       " 27373,\n",
       " 7587,\n",
       " 6460,\n",
       " 2007,\n",
       " 114265,\n",
       " 3795,\n",
       " 626,\n",
       " 167064,\n",
       " 25906,\n",
       " 5328,\n",
       " 127096,\n",
       " 1564,\n",
       " 124851,\n",
       " 190,\n",
       " 86237,\n",
       " 3073,\n",
       " 27523,\n",
       " 68486,\n",
       " 187717,\n",
       " 998,\n",
       " 40,\n",
       " 3925,\n",
       " 120130,\n",
       " 1349,\n",
       " 71268,\n",
       " 6086,\n",
       " 3473,\n",
       " 26147,\n",
       " 299,\n",
       " 69860,\n",
       " 140627,\n",
       " 4441,\n",
       " 1151,\n",
       " 3086,\n",
       " 5088,\n",
       " 1310,\n",
       " 184245,\n",
       " 86721,\n",
       " 82744,\n",
       " 38388,\n",
       " 79274,\n",
       " 90943,\n",
       " 4495,\n",
       " 4444,\n",
       " 495,\n",
       " 100556,\n",
       " 97866,\n",
       " 84414,\n",
       " 6408,\n",
       " 120635,\n",
       " 467,\n",
       " 109687,\n",
       " 4142,\n",
       " 2512,\n",
       " 102084,\n",
       " 3266,\n",
       " 4402,\n",
       " 3787,\n",
       " 108795,\n",
       " 5059,\n",
       " 3851,\n",
       " 3531,\n",
       " 102194,\n",
       " 3678,\n",
       " 95149,\n",
       " 179135,\n",
       " 110501,\n",
       " 3303,\n",
       " 26249,\n",
       " 70946,\n",
       " 100083,\n",
       " 7071,\n",
       " 117531,\n",
       " 2151,\n",
       " 64499,\n",
       " 3223,\n",
       " 26366,\n",
       " 5746,\n",
       " 26073,\n",
       " 102217,\n",
       " 99,\n",
       " 55167,\n",
       " 5537,\n",
       " 7756,\n",
       " 5477,\n",
       " 128914,\n",
       " 5833,\n",
       " 6306]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_recs = predictions.select(\"movieId\").distinct().rdd.map(lambda x: x.movieId).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc106df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 348:=================================================>  (190 + 10) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 1.0, Precision function 2 0.12857142857142864 MAP 0.9811507936507937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Tests start here\n",
    "positive_rating_threshold = 0.0\n",
    "eval_data = spark.createDataFrame(val.collect()).alias(\"eval_data\")\n",
    "predictions = spark.createDataFrame(temp.collect()).alias(\"predictions\")\n",
    "\n",
    "eval_data = eval_data.withColumn(\"e_concat\",concat_ws('-','userId','movieId'))\n",
    "predictions = predictions.withColumn(\"p_concat\",concat_ws('-','userId','movieId'))\n",
    "# predictions = labels.withColumn(\"userId\",col(\"userId\").cast(\"long\")).withColumn(\"movieId\",col(\"movieId\").cast(\"long\"))\n",
    "#Condition Joins\n",
    "\n",
    "# cond = [eval_data.userId == predictions.userId, eval_data.movieId == predictions.movieId]\n",
    "#Join labels and predictions on [userId,movieId]\n",
    "# inter = eval_data.join(predictions, (predictions.userId == eval_data.userId)&(predictions.movieId == eval_data.movieId), how='inner')\\\n",
    "# .select(predictions.userId, eval_data.rating,predictions.movieId)\n",
    "inter = eval_data.join(predictions, col('p_concat') == col('e_concat'), how='inner')\\\n",
    ".select(predictions.userId, eval_data.rating,predictions.movieId)#.drop(eval_data.movieId,eval_data.userId,eval_data.concat)\n",
    "\n",
    "inter = spark.createDataFrame(inter.collect())\n",
    "temp = inter\n",
    "inter = inter.select(col(\"userId\"),col(\"movieId\"),col(\"rating\"))#.where(col(\"userId\")==603)\n",
    "\n",
    "pos = inter.select(col(\"userId\"),col(\"movieId\"),col(\"rating\")).where(col(\"rating\")>0.0)#\n",
    "\n",
    "pos = pos.select(\"userId\",\"movieId\").withColumn(\"movieId\",col(\"movieId\").cast(\"double\"))\n",
    "pos = pos.groupBy(col(\"userId\")).agg(collect_list(col('movieId')).alias('movieId'))\n",
    "\n",
    "#Repeat double casting + collapse procedure for labels\n",
    "inter = inter.withColumn(\"movieId\",col(\"movieId\").cast(\"double\"))\n",
    "inter = inter.groupBy('userId').agg(collect_list(col(\"movieId\")).alias(\"movieId\"))\n",
    "\n",
    "#Join\n",
    "ranking_metrics_data = inter.join(pos, inter.userId == pos.userId,how='inner')\\\n",
    ".select(inter.userId, inter.movieId,pos.movieId).rdd.map(lambda row: (row[1], row[2]))\n",
    "\n",
    "\n",
    "#print(ranking_metrics_data.collect())\n",
    "\n",
    "metrics = RankingMetrics(ranking_metrics_data)\n",
    "\n",
    "precision = metrics.recallAt(100)\n",
    "precision2 = metrics.precisionAt(10)\n",
    "MAP = metrics.meanAveragePrecision\n",
    "print(f\"Precision {precision}, Precision function 2 {precision2} MAP {MAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03e9fc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Len: 60250 Val Len: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 471:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping movieIds: [(79, 3266), (286, 6086), (567, 3266), (398, 26147), (96, 299), (585, 27373), (191, 496), (603, 299), (191, 99), (195, 190), (377, 4294), (544, 626)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_leakage_check(train, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eeee0139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 388:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|userId|movieId|\n",
      "+------+-------+\n",
      "|   148|  71268|\n",
      "|   148|   6306|\n",
      "|   148|   6732|\n",
      "|   148|   3795|\n",
      "|   148|  55167|\n",
      "|   148| 120130|\n",
      "|   148|  26366|\n",
      "|   148|   7071|\n",
      "|   148|    876|\n",
      "|   148| 184245|\n",
      "|   148|   4441|\n",
      "|   148|  84273|\n",
      "|   148|   4142|\n",
      "|   148|  26073|\n",
      "|   148|  25906|\n",
      "|   148|  86237|\n",
      "|   148|  26249|\n",
      "|   148| 117531|\n",
      "|   148|  64499|\n",
      "|   148| 179135|\n",
      "+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970f29a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ranking_metrics_data = label_inner_predictions.join(pos_label_inner_prediction, label_inner_predictions.userId == pos_label_inner_prediction.userId,how='inner')\\\n",
    "# .select(label_inner_predictions.userId, label_inner_predictions.movieId,pos_label_inner_prediction.movieId).rdd.map(lambda row: (row[0],row[1], row[2]))\n",
    "# a= prediction_checker(ranking_metrics_data,val,0)\n",
    "# tuple_checker(ranking_metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "964ebd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_OTB_ranking_metrics(preds,labels,k):\n",
    "    perUserPredictedItemsDF = preds \\\n",
    "        .select('userId', 'movieId')\\\n",
    "        .groupBy('userId') \\\n",
    "        .agg(expr('collect_list(movieId) as movieId'))\n",
    "\n",
    "    windowSpec = Window.partitionBy('userId').orderBy(col('date').desc())\n",
    "    perUserActualItemsDF = labels \\\n",
    "        .select('userId', 'movieId', 'date', rank().over(windowSpec).alias('rank')) \\\n",
    "        .where('rank <= {0}'.format(k)) \\\n",
    "        .groupBy('userId') \\\n",
    "        .agg(expr('collect_list(movieId) as movieId'))\n",
    "\n",
    "    perUserItemsRDD = perUserPredictedItemsDF.join(broadcast(perUserActualItemsDF), 'userId', 'inner') \\\n",
    "        .rdd \\\n",
    "        .map(lambda row: (row[1], row[2]))\n",
    "    rankingMetrics = RankingMetrics(perUserItemsRDD)\n",
    "    return rankingMetrics.meanAveragePrecision, rankingMetrics.ndcgAt(k), rankingMetrics.ndcgAt(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26c2bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.073334984382854e-05, 0.0010301271058742066, 0.0010301271058742057)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_OTB_ranking_metrics(temp,val,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "31a280a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_CUSTOM_ranking_metrics(preds,labels):\n",
    "    \"\"\"\n",
    "    Take in predictions and labels PySpark DataFrames\n",
    "    Step 1) Collect movie_recs into a Python set\n",
    "    Step 2) Collapse labels into a list of seen movies (orderBy to preserve ordering)\n",
    "    Step 3) Collapse labels that have been filtered by positive ratings into list of seen movies (also OrderBy)\n",
    "    Step 4) Iterate over the sets and see if there's an intersection between label movies sets and movie recs sets\n",
    "    Step 5) If there is an intersection, calculate the precision\n",
    "    Step 6) Precision is calculated by taking the length of intersection of positive ratings label sets and movie \n",
    "            rec set, divided by the length of the label seen movies set intersected with movie rec set\n",
    "    \"\"\"\n",
    "    #Dummy var\n",
    "    precision_arr = []   \n",
    "    #Collect movie_recs into set\n",
    "    movie_recs = set(preds.select(\"movieId\").distinct().rdd.map(lambda x: x.movieId).collect())\n",
    "\n",
    "    #Collect val labels into list\n",
    "    label_set = labels \\\n",
    "    .select('userId', 'movieId')\\\n",
    "    .groupBy('userId') \\\n",
    "    .agg(expr('collect_list(movieId) as movieId'))\\\n",
    "    .orderBy(\"userId\")\\\n",
    "    .rdd.map(lambda x: x.movieId).collect()\n",
    "    \n",
    "    #Collect val labels into list\n",
    "    pos_set = labels \\\n",
    "    .select('userId', 'movieId')\\\n",
    "    .where(col(\"rating\")>0)\\\n",
    "    .groupBy('userId') \\\n",
    "    .agg(expr('collect_list(movieId) as movieId'))\\\n",
    "    .orderBy(\"userId\")\\\n",
    "    .rdd.map(lambda x: x.movieId).collect()\n",
    "    \n",
    "    #Iterate for every userId\n",
    "    for i in range(len(label_set)):\n",
    "        #See if there's an intersection between seen movies and recs\n",
    "        temp_label_set = set(label_set[i]) #Create set of watched movies for user i\n",
    "        #get the length of intersection between seen movies and reccomended\n",
    "        intersection = len(temp_label_set.intersection(movie_recs)) \n",
    "        #If there's an intersection continue\n",
    "        if intersection > 0:\n",
    "            #Get positive set of seen movies for user i\n",
    "            temp_pos_set = set(pos_set[i])\n",
    "            #Get intersection between positively rated and movie_recs for user i\n",
    "            positive_intersection = len(temp_pos_set.intersection(movie_recs))\n",
    "            precision_arr.append(positive_intersection/intersection)\n",
    "                \n",
    "    precision_arr = np.array(precision_arr)\n",
    "    return precision_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ae1fc18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "precision_arr = baseline_CUSTOM_ranking_metrics(temp,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cd9e3724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.         1.         1.         1.\n",
      " 0.         1.         0.66666667 0.5        1.         1.\n",
      " 1.         1.         1.         1.         1.         0.\n",
      " 1.         1.         0.75       0.         0.         0.\n",
      " 0.         0.         0.         1.         0.        ] 0.6178160919540229\n"
     ]
    }
   ],
   "source": [
    "print(precision_arr,precision_arr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720ba1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perUserActualItemsDF = val \\\n",
    ".select('userId', 'movieId')\\\n",
    ".groupBy('userId') \\\n",
    ".agg(expr('collect_list(movieId) as movieId')).orderBy(\"userId\").rdd.map(lambda x: x.movieId).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "59ba0966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pos = val \\\n",
    ".select('userId', 'movieId')\\\n",
    ".where(col(\"rating\")>0)\\\n",
    ".groupBy('userId') \\\n",
    ".agg(expr('collect_list(movieId) as movieId')).orderBy(\"userId\").rdd.map(lambda x: x.movieId).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "94c2627d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[318,\n",
       " 115713,\n",
       " 86345,\n",
       " 80906,\n",
       " 131724,\n",
       " 333,\n",
       " 77455,\n",
       " 3578,\n",
       " 79132,\n",
       " 68157,\n",
       " 106782,\n",
       " 58559]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(pos[0]).intersection(set(perUserActualItemsDF[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f085d926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perUserActualItemsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d31a2c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "movie_recs = set(temp.select(\"movieId\").distinct().rdd.map(lambda x: x.movieId).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "493805e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "107a744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498374a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
